# -*- coding: utf-8 -*-
"""Another copy of Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VlK6K8QpvSfslDbMedcTNoGxiYa1eIlH

Introduction to the Dataset

This dataset contains information on 4,960 vehicles, including details about their specifications, mileage, fuel type, and price. It is structured with 11 columns, each representing different characteristics of the vehicles.


Dataset Features
carID - Unique identifier for each car.

brand - Car manufacturer (e.g., Audi, VW, Hyundai).

model - Model name of the vehicle.

year - Year of manufacture.

transmission - Type of transmission (e.g., Manual, Automatic).

mileage - Distance the car has been driven (in miles).

fuelType - Type of fuel used (e.g., Petrol, Diesel).

tax - Annual tax associated with the vehicle.

mpg - Miles per gallon (fuel efficiency).

engineSize - Size of the engine in liters.

price - Market price of the car

 (target variable for prediction).

Potential Analysis & Predictions
Price Prediction: Based on car features, predict the selling price.

Fuel Efficiency Analysis: Determine factors affecting MPG.

Brand & Model Trends: Identify which brands and models have better resale values.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv("/content/Vehicle analysis prediction.csv")
df

"""This dataset contains information on 4,960 vehicles, including details about their specifications, mileage, fuel type, and price. It is structured with 11 columns, each representing different characteristics of the vehicles."""

df.isnull().sum()

"""THERE ARE NO NULL VALUES IN THE DATASET

"""

df.info()

df.head()

df.tail()

df.sample(10)

df.describe()

df.shape

df.index

df.columns

"""COLUMNS IN THE TABLE

"""

df.dtypes

"""THERE DATATYPES IN THIS DATASET ARE INT AND FLOAT"""

df.nunique()

"""Returns no of unique values in each column"""

df.count()

"""Total no of observations present in datset for each column"""

df['brand'].value_counts()

"""To count the number of occurrences of each unique value in column

# DATA VISUVALIZATION

THE DISTRIBUTION SHOWS THE BRANDS AND THEIR PERCENTANGE OF DISTRIBUTION

THE BAR GRAPH SHOWS THE SALES OF CAR BRAND
"""

plt.figure(figsize=(8, 6))

sns.histplot(df['price'], bins=20, kde=True, color='skyblue')

plt.title("Histogram with KDE for Price")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.show()

"""THE HISTOGRAM SHOWS ABOUT THE PRICE"""

plt.figure(figsize=(10, 5))

markerline, stemlines, baseline = plt.stem(df['year'], df['price'], linefmt='r-', markerfmt='bo', basefmt='g-')

plt.setp(stemlines, linewidth=1.5)
plt.setp(markerline, markersize=5)
plt.title("Stem Plot of Year vs Price")
plt.xlabel("Year")
plt.ylabel("Price")
plt.show()

"""THE STEM PLOT SHOWS HOW THE PRICE IN DIFFERENT YEARS VARIES"""

from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(10, 6))

ax = fig.add_subplot(111, projection='3d')

ax.scatter(df['year'], df['price'], df['mileage'], c=df['price'], cmap='coolwarm', marker='o')

ax.set_xlabel('Year')
ax.set_ylabel('Price')
ax.set_zlabel('Mileage')
ax.set_title('3D Scatter Plot of Year, Price, and Mileage')
plt.show()

"""3D PLOT THAT GIVES A BRIEF ABOUT YEAR,PRICE AND MILEAGE"""

plt.figure(figsize=(12, 6))

sns.stripplot(x=df['brand'], y=df['price'], jitter=True, palette="Set2", alpha=0.7)

plt.title("Strip Plot of Brand vs Price")
plt.xlabel("Brand")
plt.ylabel("Price")
plt.xticks(rotation=45)
plt.show()

numerical_cols = df.select_dtypes(include=['number']).columns

sns.pairplot(df[numerical_cols], diag_kind='kde', corner=True)
plt.show()

"""
PAIR PLOT FOR COLUMNS IN DATASET WHICH ARE NUMERICAL VALUES



"""

plt.figure(figsize=(8, 6))

sns.boxplot(x=df['transmission'], y=df['price'], palette="Set2")

plt.title("Box Plot of Price by Transmission Type")
plt.xlabel("Transmission Type")
plt.ylabel("Price ($)")
plt.xticks(rotation=45)

plt.show()

plt.figure(figsize=(12, 6))

df.select_dtypes(include=['number']).boxplot(rot=45)
plt.title("Box Plot for Outlier Detection in Numerical Columns")

plt.show()

"""OUTLIERS DETECTION USING BOXPPLOT"""

plt.figure(figsize=(8, 6))
sns.scatterplot(x=df['mileage'], y=df['price'], alpha=0.5)

plt.title("Scatter Plot of Price vs Mileage (Outlier Detection)")
plt.xlabel("Mileage")
plt.ylabel("Price")

plt.show()

df_cleaned = df.copy()

numerical_cols = df_cleaned.select_dtypes(include=np.number).columns

for col in numerical_cols:
    Q1 = df_cleaned[col].quantile(0.25)
    Q3 = df_cleaned[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]

print(f"Original dataset rows: {len(df)}")
print(f"Dataset after outlier removal: {len(df_cleaned)}")

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_cleaned[numerical_cols] = scaler.fit_transform(df_cleaned[numerical_cols])

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder


label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

threshold = df['price'].median()
df['price_binary'] = (df['price'] > threshold).astype(int)

X = df.drop(columns=['price', 'price_binary'])
y = df['price_binary']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred_prob = model.predict_proba(X_test)[:, 1]

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_prob)
accuracy = model.score(X_test, y_test) * 100

print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)
print("Mean Squared Error:", mse)
print("R-squared Score:", r2)
print("Model Accuracy:", accuracy, "%")
print("ROC-AUC Score:", roc_auc)

from sklearn.preprocessing import LabelEncoder

categorical_cols = df_cleaned.select_dtypes(exclude=['number']).columns
for col in categorical_cols:
    le = LabelEncoder()
    df_cleaned[col] = le.fit_transform(df_cleaned[col])

from sklearn.model_selection import train_test_split


target_column = 'price'
X = df.drop(columns=[target_column])
y = df[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


target_column = 'price'

X = df.drop(columns=[target_column])
y = df[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)
print("Mean Squared Error:", mse)
print("R-squared Score:", r2)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

target_column = 'price'

X = df.drop(columns=[target_column])
y = df[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
accuracy = model.score(X_test, y_test) * 100

print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)
print("Mean Squared Error:", mse)
print("R-squared Score:", r2)
print("Model Accuracy:", accuracy, "%")

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score

threshold = df['price'].median()
df['price_binary'] = (df['price'] > threshold).astype(int)

X = df.drop(columns=['price', 'price_binary'])
y = df['price_binary']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_pred_prob = model.predict_proba(X_test)[:, 1]

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_prob)
accuracy = model.score(X_test, y_test) * 100
print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)
print("Mean Squared Error:", mse)
print("R-squared Score:", r2)
print("Model Accuracy:", accuracy, "%")
print("ROC-AUC Score:", roc_auc)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score


target_column = 'price'

categorical_cols = df.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_cols:
    label_encoders[col] = LabelEncoder()
    df[col] = label_encoders[col].fit_transform(df[col])

X = df.drop(columns=[target_column])
y = df[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
accuracy = model.score(X_test, y_test) * 100
print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)
print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared Score:", r2)
print("Model Accuracy:", accuracy, "%")

"""THE MODEL RANDOM FOREST IS BEST SUITABLE TO PREDICT THE TARGET COLUMN "PRICE" AS IT GIVES THE BEST ACCURACY AND RESLT"""

